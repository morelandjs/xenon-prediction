"""
Generates plots / figures when run as a script.
Plot files are placed in the :file:`plots` directory.

By default, simply running ``python -m src.plots`` generates **ALL** plots,
which may not be desired.  Instead, one can pass a list of plots to generate:
``python -m src.plots plot1 plot2 ...``.  The full list of plots is shown in
the usage information ``python -m src.plots --help``.

Typing can be reduced by using shell brace expansion, e.g. ``python -m
src.plots observables_{design,posterior}`` for both ``observables_design`` and
``observables_posterior``.  In addition, plots may be given as paths to plot
filenames, which enables shell globbing, e.g. ``python -m src.plots
plots/observables_*``.

In the code, each plot is generated by a function tagged with the ``@plot``
decorator.
"""

import itertools
import logging
from pathlib import Path
import subprocess
import tempfile
import warnings

import hsluv
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import lines
from matplotlib import patches
from matplotlib import ticker

from . import workdir, systems, parse_system, expt, model


fontsmall, fontnormal, fontlarge = 5, 6, 7
offblack = '#262626'
aspect = 1/1.618
resolution = 72.27
textwidth = 307.28987/resolution
textheight = 261.39864/resolution
fullwidth = 350/resolution
fullheight = 270/resolution

plt.rcdefaults()
plt.rcParams.update({
    'font.family': 'sans-serif',
    'font.sans-serif': ['Lato'],
    'mathtext.fontset': 'custom',
    'mathtext.default': 'it',
    'mathtext.rm': 'sans',
    'mathtext.cal': 'sans',
    'font.size': fontnormal,
    'legend.fontsize': fontnormal,
    'axes.labelsize': fontnormal,
    'axes.titlesize': fontlarge,
    'xtick.labelsize': fontsmall,
    'ytick.labelsize': fontsmall,
    'font.weight': 400,
    'axes.labelweight': 400,
    'axes.titleweight': 400,
    'lines.linewidth': .5,
    'lines.markersize': 3,
    'lines.markeredgewidth': 0,
    'patch.linewidth': .5,
    'axes.linewidth': .4,
    'xtick.major.width': .4,
    'ytick.major.width': .4,
    'xtick.minor.width': .4,
    'ytick.minor.width': .4,
    'xtick.major.size': 1.2,
    'ytick.major.size': 1.2,
    'xtick.minor.size': .8,
    'ytick.minor.size': .8,
    'xtick.major.pad': 1.5,
    'ytick.major.pad': 1.5,
    'axes.formatter.limits': (-5, 5),
    'axes.spines.top': False,
    'axes.spines.right': False,
    'axes.labelpad': 3,
    'text.color': offblack,
    'axes.edgecolor': offblack,
    'axes.labelcolor': offblack,
    'xtick.color': offblack,
    'ytick.color': offblack,
    'legend.numpoints': 1,
    'legend.scatterpoints': 1,
    'legend.frameon': False,
    'image.cmap': 'Blues',
    'image.interpolation': 'none',
    'pdf.fonttype': 42
})


plotdir = workdir / 'plots'
plotdir.mkdir(exist_ok=True)

plot_functions = {}


def run_cmd(*args):
    """
    Run and log a subprocess.
    """
    cmd = ' '.join(args)
    logging.info('running command: %s', cmd)

    try:
        proc = subprocess.run(
            cmd.split(), check=True,
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            universal_newlines=True
        )
    except subprocess.CalledProcessError as e:
        logging.error(
            'command failed with status %d:\n%s',
            e.returncode, e.output.strip('\n')
        )
        raise
    else:
        logging.debug(
            'command completed successfully:\n%s',
            proc.stdout.strip('\n')
        )
        return proc


def plot(f):
    """
    Plot function decorator.  Calls the function, does several generic tasks,
    and saves the figure as the function name.

    """
    def wrapper(*args, **kwargs):
        logging.info('generating plot: %s', f.__name__)
        f(*args, **kwargs)

        fig = plt.gcf()

        if not fig.get_tight_layout():
            set_tight(fig)

        plotfile = plotdir / '{}.png'.format(f.__name__)
        fig.savefig(str(plotfile), dpi=300)
        logging.info('wrote %s', plotfile)
        plt.close(fig)

    plot_functions[f.__name__] = wrapper

    return wrapper


def set_tight(fig=None, **kwargs):
    """
    Set tight_layout with a better default pad.

    """
    if fig is None:
        fig = plt.gcf()

    kwargs.setdefault('pad', .1)
    fig.set_tight_layout(kwargs)


def auto_ticks(ax, axis='both', minor=False, **kwargs):
    """
    Convenient interface to matplotlib.ticker locators.

    """
    axis_list = []

    if axis in {'x', 'both'}:
        axis_list.append(ax.xaxis)
    if axis in {'y', 'both'}:
        axis_list.append(ax.yaxis)

    for axis in axis_list:
        axis.get_major_locator().set_params(**kwargs)
        if minor:
            axis.set_minor_locator(ticker.AutoMinorLocator(minor))


def darken(rgb, amount=.5):
    """
    Darken a color by the given amount in HSLuv space.

    """
    h, s, l = hsluv.rgb_to_hsluv(rgb)
    return hsluv.hsluv_to_rgb((h, s, (1 - amount)*l))


def obs_color_hsluv(obs, subobs):
    """
    Return a nice color for the given observable in HSLuv space.
    Use obs_color() to obtain an RGB color.

    """
    if obs in {'dNch_deta', 'pT_fluct'}:
        return 250, 90, 55

    if obs == 'dET_deta':
        return 10, 65, 55

    if obs in {'dN_dy', 'mean_pT'}:
        return dict(
            pion=(210, 85, 70),
            kaon=(130, 88, 68),
            proton=(30, 90, 62),
        )[subobs]

    if obs == 'vnk':
        return {
            (2, 2): (230, 90, 65),
            (2, 4): (262, 80, 63),
            (3, 2): (150, 90, 67),
            (4, 2): (310, 70, 50),
        }[subobs]

    raise ValueError('unknown observable: {} {}'.format(obs, subobs))


def obs_color(obs, subobs):
    """
    Return a nice color for the given observable.

    """
    return hsluv.hsluv_to_rgb(obs_color_hsluv(obs, subobs))


def _observables_plots():
    """
    Metadata for observables plots.

    """
    def id_parts_plots(obs):
        return [(obs, species, dict(label=label)) for species, label in [
            ('pion', '$\pi$'), ('kaon', '$K$'), ('proton', '$p$')
        ]]

    return [
        dict(
            title='Yields',
            ylabel=(
                r'$dN_\mathrm{ch}/d\eta,\ dN/dy,\ dE_T/d\eta\ [\mathrm{GeV}]$'
            ),
            ylim=(1, 1e5),
            yscale='log',
            height_ratio=1.5,
            subplots=[
                ('dNch_deta', None, dict(label=r'$N_\mathrm{ch}$', scale=25)),
                ('dET_deta', None, dict(label=r'$E_T$', scale=5)),
                *id_parts_plots('dN_dy')
            ]
        ),
        dict(
            title='Mean $p_T$',
            ylabel=r'$\langle p_T \rangle$ [GeV]',
            ylim=(0, 1.7),
            subplots=id_parts_plots('mean_pT')
        ),
        dict(
            title='Mean $p_T$ fluctuations',
            ylabel=r'$\delta p_T/\langle p_T \rangle$',
            ylim=(0, .04),
            subplots=[('pT_fluct', None, dict())]
        ),
        dict(
            title='Flow cumulants',
            ylabel=r'$v_n\{2\}$',
            ylim=(0, .12),
            subplots=[
                ('vnk', (n, 2), dict(label='$v_{}$'.format(n)))
                for n in [2, 3, 4]
            ]
        )
    ]


@plot
def observables_map():
    """
    Model observables and ratio to experiment at the maximum a posteriori
    (MAP) estimate.

    """
    plots = _observables_plots()
    systems = 'PbPb5020', 'XeXe5440'

    ylim = {
        'Yields': (2, 1e5),
        'Flow cumulants': (0, .15),
        'Mean $p_T$': (0, 1.7),
        'Mean $p_T$ fluctuations': (0, .045),
    }

    for n, p in enumerate(plots):
        p['ylim'] = ylim[p['title']]
        if p['title'] == 'Flow cumulants':
            move_index = n
            p.update(
                ylabel=r'$v_n\{k\}$',
                subplots=[
                    ('vnk', nk, dict(label='$v_{}\{{{}\}}$'.format(*nk)))
                    for nk in [(2, 2), (2, 4), (3, 2), (4, 2)]
                ],
                legend=True
            )

    plots.insert(1, plots.pop(move_index))

    ncols = int(len(plots)/2)

    fig, axes = plt.subplots(
        nrows=4, ncols=ncols,
        figsize=(.8*fullwidth, .4*ncols*fullwidth),
        gridspec_kw=dict(
            height_ratios=list(itertools.chain.from_iterable(
                (p.get('height_ratio', 1), .4) for p in plots[::ncols]
            ))
        )
    )

    labels = {}
    handles = dict(expt={}, model={})

    for plot, ax, ratio_ax in zip(plots, axes[::2].flat, axes[1::2].flat):
        for system, (obs, subobs, opts) in itertools.product(
                systems, plot['subplots']
        ):
            color = obs_color(obs, subobs)
            scale = opts.get('scale')

            linestyle, fill_markers = {
                'PbPb5020': ('solid', True),
                'XeXe5440': ('dashed', False),
            }[system]

            x = model.map_data[system][obs][subobs]['x']
            y = model.map_data[system][obs][subobs]['Y']

            if scale is not None:
                y = y*scale

            ax.plot(x, y, color=color, ls=linestyle)
            handles['model'][system] = \
                lines.Line2D([], [], color=offblack, ls=linestyle)

            if 'label' in opts and (obs, subobs) not in labels:
                labels[obs, subobs] = ax.text(
                    x[-1] + 3, y[-1],
                    opts['label'],
                    color=darken(color), ha='left', va='center'
                )

            try:
                dset = expt.data[system][obs][subobs]
            except KeyError:
                continue

            x = dset['x']
            yexp = dset['y']
            yerr = dset['yerr']
            yerrstat = yerr.get('stat')
            yerrsys = yerr.get('sys', yerr.get('sum'))

            if scale is not None:
                yexp = yexp*scale
                if yerrstat is not None:
                    yerrstat = yerrstat*scale
                if yerrsys is not None:
                    yerrsys = yerrsys*scale

            handles['expt'][system] = ax.errorbar(
                x, yexp, yerr=yerrstat, fmt='o', ms=1.7,
                capsize=0, color=offblack,
                mfc=(offblack if fill_markers else '.9'),
                mec=offblack, mew=(0 if fill_markers else .25),
                zorder=1000
            )

            ax.fill_between(
                x, yexp - yerrsys, yexp + yerrsys,
                facecolor='.9', zorder=-10,
            )

        for obs, subobs, opts in plot['subplots']:
            x_pbpb, y_pbpb, x_xexe, y_xexe = [
                    model.map_data[sys][obs][subobs][var]
                    for (sys, var) in itertools.product(systems, ['x', 'Y'])
                    ]

            color = obs_color(obs, subobs)
            try:
                ratio_ax.plot(x_pbpb, y_xexe/y_pbpb, color=color)
            except:
                pass

        if plot.get('yscale') == 'log':
            ax.set_yscale('log')
            ax.minorticks_off()
        else:
            auto_ticks(ax, 'y', nbins=4, minor=2)

        for a in [ax, ratio_ax]:
            a.set_xlim(0, 80)
            auto_ticks(a, 'x', nbins=5, minor=2)

        if ratio_ax.is_last_row():
            ratio_ax.set_xlabel('Centrality %')

        ax.set_ylim(plot['ylim'])
        ax.set_ylabel(plot['ylabel'])

        empty = patches.Rectangle(
            (0,0), 1, 1, fill=False, edgecolor='none', visible=False
        )
        expt_handles = [handles['expt']['PbPb5020'], empty]
        model_handles = [handles['model'][s] for s in systems]

        if plot.get('legend'):
            ax.legend(
                model_handles + expt_handles,
                ['', '', 'Pb+Pb, 5.02 TeV', 'Xe+Xe, 5.44 TeV'],
                ncol=2, loc='upper left', bbox_to_anchor=(0, .94),
                columnspacing=0, handletextpad=0
            )

        ax.text(
            .5, 1 if ax.is_first_row() else .97, plot['title'],
            transform=ax.transAxes, ha='center', va='top',
            size=plt.rcParams['axes.labelsize']
        )

        ratio_ax.axhline(1, lw=.5, color='0.5', zorder=-100)
        ratio_ax.axhspan(.8, 1.2, color='0.93', zorder=-200)
        ratio_ax.set_ylim(.5, 1.5)
        ratio_ax.set_ylabel('Ratio')
        ratio_ax.text(
            ratio_ax.get_xlim()[1], .8, '±20%',
            color='.6', zorder=-50,
            ha='right', va='bottom',
            size=plt.rcParams['xtick.labelsize']
        )

    set_tight(fig)


def cross_section_fit(x):
    """
    Polynomial fit to the inelastic nucleon-nucleon
    cross section as a function of log(sqrts)

    """
    cross_sections = [
        (0.20, 4.23),
        (2.76, 6.40),
        (5.02, 7.00),
        (7.00, 7.32),
    ]

    sqrts, sigma_inel = zip(*cross_sections)
    coeff = np.polyfit(np.log(sqrts), sigma_inel, 2)

    return np.polyval(coeff, x)


def dNchdeta_fit(x):
    """
    Power law fit to Pb+Pb dNch/deta
    in 0-10% centrality using 2.76 and 5.02 TeV
    data.

    """
    dNchdeta_central = [
        (2.76, 1447.5),
        (5.02, 1764.0),
    ]

    (x0, F0), (x1, F1) = dNchdeta_central

    # see https://en.wikipedia.org/wiki/Log-log_plot
    return F0*(x/x0)**(np.log(F1/F0)/np.log(x1/x0))


@plot
def entropy_norm():
    """
    Determine Trento entropy normalization at 5.44 TeV
    from experimental data and Bayesian calibration at
    2.76, 5.02 TeV.

    """
    width = .7*textwidth
    fig = plt.figure(figsize=(width, aspect*width))

    dNchdeta_central = [
        (2.76, 1447.5),
        (5.02, 1764.0),
    ]

    # plot dNch/deta 0-10% fit function
    x = np.linspace(2, 7, 100)
    plt.plot(x, dNchdeta_fit(x))

    # plot dNch/deta measurements
    for measurement in dNchdeta_central:
        plt.plot(*measurement, 'o', label=' ')

    # plot dNch/deta Xe+Xe 5.44 TeV prediction
    plt.plot(5.44, dNchdeta_fit(5.44), 'o',
             mfc='white', mew=.5, label=' ')

    # plot trento predictions
    handles, labels = plt.gca().get_legend_handles_labels()
    for n, s_gev in enumerate([2760, 5020, 5440]):

        s_tev = s_gev/1000.
        fname = 'model_output/map/PbPb{}.init'.format(s_gev)

        minbias_mult = np.loadtxt(fname, usecols=(3,))
        mult = np.sort(minbias_mult)[-1000:].mean()
        norm = dNchdeta_fit(s_tev)/mult

        plt.annotate(
            '{} TeV'.format(s_tev),
            xy=(s_tev + .3, dNchdeta_fit(s_tev)),
            xycoords='data', ha='left', va='top',
        )

        labels[n] = '{0:.2f} [arb]'.format(norm)

    plt.xlabel(r'$\sqrt{s_\mathrm{NN}}$ [TeV]')
    plt.ylabel(r'$(dN_\mathrm{ch}/d\eta)(0–10\%)$')
    plt.title('Trento energy dependence')

    legend = plt.legend(handles, labels, title='Pb+Pb norm')

    for t in legend.get_texts():
        t.set_ha('right')
        t.set_position((100, 0))

    set_tight(fig)

@plot
def xenon_cross_section():
    """
    Extrapolate Xe+Xe 5.44 TeV cross section
    from experimental cross section measurements
    at other beam energies.

    """
    # figure size
    width = .7*textwidth
    fig = plt.figure(figsize=(width, aspect*width))

    # experimental cross sections
    cross_sections = [
        (0.20, 4.23),
        (2.76, 6.40),
        (5.02, 7.00),
        (7.00, 7.32),
    ]

    sqrts, sigma_inel = zip(*cross_sections)
    plt.plot(np.log(sqrts), sigma_inel, 'o', mew=.5, zorder=1)

    # plot fit
    x = np.linspace(-2, 3, 100)
    plt.plot(x, cross_section_fit(x), zorder=0)

    # predict xenon
    xenon_sqrts = 5.44
    xenon_sigma_inel = cross_section_fit(np.log(xenon_sqrts))
    plt.plot(np.log(xenon_sqrts), xenon_sigma_inel, 'o', zorder=1)

    plt.xlabel(r'$\log(\sqrt{s_\mathrm{NN}})$')
    plt.ylabel(r'$\sigma_\mathrm{NN}^\mathrm{inel}$')

    label = ''.join([
        r'$\sigma_\mathrm{NN}^\mathrm{inel}$',
        r'$={0:.2f}$ fm$^2$'.format(xenon_sigma_inel)
    ])

    plt.annotate(
        label, xy=(np.log(xenon_sqrts), xenon_sigma_inel),
        xycoords='data', ha='left', va='top'
    )

    plt.title(r'Xe+Xe, $\sqrt{s_\mathrm{NN}}=5.44$ TeV cross section')
    set_tight(fig)


def split_cent_bins(array, bins):
    """
    Split an array into chunks for each centrality bin. The
    array must already be sorted by centrality along its first axis.

    """
    for (a, b) in bins:
        i, j = (int(array.shape[0]*c/100) for c in (a, b))
        yield array[i:j]


@plot
def nch_per_npart():
    """
    Charged particle density at mid-rapidity per nucleon participant
    pair (dNch/deta)/(Npart/2).

    """
    width = .7*textwidth
    fig = plt.figure(figsize=(width, aspect*width))

    """
    ALICE (dNch/deta)/(Npart/2) for Pb-Pb at 5.02 TeV

    Divides experimentally measured (dNch/deta) by ALICE Glauber model Npart.

    Reference: www.hepdata.net/record/ins1410589

    """
    alice_pbpb = {
        'cent_low': [0, 2.5, 5, 7.5, 10, 20, 30, 40, 50, 60, 70],
        'cent_high': [2.5, 5, 7.5, 10, 20, 30, 40, 50, 60, 70, 80],
        'npart': [398, 372.2, 345.6, 320.1, 263, 188, 131, 86.3, 53.6, 30.4, 15.6],
        'npart_err': [2, 3, 4, 4, 4, 3, 2, 1.7, 1.2, .8, .5],
        'nch_per_npart': [10.23, 9.94, 9.64, 9.4, 8.98, 8.37, 7.81, 7.37, 6.84, 6.33, 5.76],
        'nch_per_npart_err': [.27, .31, .29, .29, .27, .26, .27, .32, .34, .41, .47]
    }

    cent_bins = list(zip(alice_pbpb['cent_low'], alice_pbpb['cent_high']))
    cent = [(a + b)/2 for (a, b) in cent_bins]

    plt.errorbar(
        alice_pbpb['npart'], alice_pbpb['nch_per_npart'],
        xerr=alice_pbpb['npart_err'], yerr=alice_pbpb['nch_per_npart_err'],
        color=offblack, fmt='o', label='ALICE: Pb-Pb, 5.02 TeV'
    )

    """
    Bayesian MAP (dNch/deta)/(Npart/2) for Pb-Pb, Xe-Xe at 5.02 and 5.44 TeV

    Reference: https://github.com/morelandjs/xenon-prediction

    """
    systems = [
        ('PbPb5020', r'Duke global calibr: Pb-Pb, 5.02 TeV'),
        ('XeXe5440', r'Duke global calibr: Xe-Xe, 5.44 TeV'),
    ]

    def split_cent_bins(array, bins):
        """
        Split an array into chunks for each centrality bin. The
        array must already be sorted by centrality along its first axis.

        """
        for (a, b) in bins:
            i, j = (int(array.shape[0]*c/100) for c in (a, b))
            yield array[i:j]

    for system, label in systems:
        """
        Centrality bins

        """
        cent_edges = np.linspace(0, 80, 81)
        cent_bins = [(a, b) for (a, b) in zip(cent_edges[:-1], cent_edges[1:])]
        cent = [(a + b)/2 for (a, b) in cent_bins]

        """
        Mimic ALICE MC-Glauber model Npart using TRENTO

        """
        fname = 'model_output/map/{}.alice'.format(system)
        npart, ncoll = np.loadtxt(fname, usecols=[2, 3]).T
        mult = .8*npart + .2*ncoll

        npart = np.array([
            np.mean(npart) for npart in split_cent_bins(
                npart[mult.argsort()][::-1], cent_bins
            )
        ])

        """
        Calculate (dNch/deta) / (Npart/2) from the Duke global Bayesian
        calibration. These (dNch/deta) values are calculated from the full
        collision model, trento -> freestreaming -> vishnew -> urqmd, and
        are calibrated to multiple observables.

        """
        mapfile = Path(workdir, 'model_output', 'map', '{}.dat'.format(system))
        hydro_events = model.ModelData(mapfile).events.pop()

        dnch_deta = np.array([
            np.mean(nch) for nch in split_cent_bins(
                hydro_events['dNch_deta'][::-1], cent_bins
            )
        ])

        plt.plot(npart, (2*dnch_deta/npart), label=label)

        savefile = Path('predict', '{}.txt'.format(system))
        savefile.parent.mkdir(parents=True, exist_ok=True)

        results = np.column_stack((cent, npart, dnch_deta, 2*dnch_deta/npart))
        header = 'Centrality, <Npart>, <dNch/deta>, <dNch/deta>/(<Npart>/2)'
        np.savetxt(savefile, results, fmt='%1.3f', delimiter=' ', header=header)

    plt.ylim(0, 12)
    plt.xlabel(r'$N_\mathrm{part}$')
    plt.ylabel(r'$(dN_\mathrm{ch}/d\eta)/(N_\mathrm{part}/2)$')
    plt.legend(title='Collision systems', loc=4)

    set_tight()


if __name__ == '__main__':
    import argparse
    from urllib.request import urlopen
    from matplotlib.mathtext import MathTextWarning

    # create cache directory
    cachedir = Path('model_output/map')
    cachedir.mkdir(parents=True, exist_ok=True)

    baseurl = 'https://www.phy.duke.edu/~jsm55/xenon-prediction'
    filenames = [
        'PbPb2760.init',
        'PbPb5020.init',
        'PbPb5440.init',
        'PbPb5020.alice',
        'XeXe5440.alice',
        'PbPb5020.dat',
        'XeXe5440.dat',
    ]

    # download model data
    for filename in filenames:
        cachefile = cachedir / filename
        if cachefile.exists():
            continue

        cachefile.parent.mkdir(exist_ok=True)

        logging.info('downloading model data: {}'.format(filename))
        url = '{}/{}'.format(baseurl, filename)

        with cachefile.open('wb') as f, urlopen(url) as u:
            f.write(u.read())

    warnings.filterwarnings(
        'ignore',
        category=MathTextWarning,
        message='Substituting with a symbol from Computer Modern.'
    )

    choices = list(plot_functions)

    def arg_to_plot(arg):
        arg = Path(arg).stem
        if arg not in choices:
            raise argparse.ArgumentTypeError(arg)
        return arg

    parser = argparse.ArgumentParser(description='generate plots')
    parser.add_argument(
        'plots', nargs='*', type=arg_to_plot, metavar='PLOT',
        help='{} (default: all)'.format(', '.join(choices).join('{}'))
    )
    args = parser.parse_args()

    if args.plots:
        for p in args.plots:
            plot_functions[p]()
    else:
        for f in plot_functions.values():
            f()
